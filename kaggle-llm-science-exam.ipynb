{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-25T12:17:24.313782Z","iopub.execute_input":"2023-07-25T12:17:24.314138Z","iopub.status.idle":"2023-07-25T12:17:24.318820Z","shell.execute_reply.started":"2023-07-25T12:17:24.314111Z","shell.execute_reply":"2023-07-25T12:17:24.317712Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df1 = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\ntrain_df2 = pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv')\ntrain_df3 = pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:24.485863Z","iopub.execute_input":"2023-07-25T12:17:24.486200Z","iopub.status.idle":"2023-07-25T12:17:24.611401Z","shell.execute_reply.started":"2023-07-25T12:17:24.486171Z","shell.execute_reply":"2023-07-25T12:17:24.610467Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df1, train_df3])\ntrain_df = pd.concat([train_df, train_df2])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:24.645709Z","iopub.execute_input":"2023-07-25T12:17:24.646365Z","iopub.status.idle":"2023-07-25T12:17:24.661553Z","shell.execute_reply.started":"2023-07-25T12:17:24.646328Z","shell.execute_reply":"2023-07-25T12:17:24.660682Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ntrain_ds = Dataset.from_pandas(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:24.823560Z","iopub.execute_input":"2023-07-25T12:17:24.823907Z","iopub.status.idle":"2023-07-25T12:17:25.738820Z","shell.execute_reply.started":"2023-07-25T12:17:24.823882Z","shell.execute_reply":"2023-07-25T12:17:25.737791Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# The path of the model checkpoint we want to use\nmodel_dir = '/kaggle/input/deberta-v3-large-hf-weights'\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:25.740852Z","iopub.execute_input":"2023-07-25T12:17:25.741392Z","iopub.status.idle":"2023-07-25T12:17:28.994831Z","shell.execute_reply.started":"2023-07-25T12:17:25.741357Z","shell.execute_reply":"2023-07-25T12:17:28.993619Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"options = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:28.996478Z","iopub.execute_input":"2023-07-25T12:17:28.997261Z","iopub.status.idle":"2023-07-25T12:17:29.003423Z","shell.execute_reply.started":"2023-07-25T12:17:28.997225Z","shell.execute_reply":"2023-07-25T12:17:29.002319Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:29.006965Z","iopub.execute_input":"2023-07-25T12:17:29.007935Z","iopub.status.idle":"2023-07-25T12:17:29.016362Z","shell.execute_reply.started":"2023-07-25T12:17:29.007902Z","shell.execute_reply":"2023-07-25T12:17:29.015397Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenized_train_ds = train_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:29.017732Z","iopub.execute_input":"2023-07-25T12:17:29.018225Z","iopub.status.idle":"2023-07-25T12:17:36.666099Z","shell.execute_reply.started":"2023-07-25T12:17:29.018192Z","shell.execute_reply":"2023-07-25T12:17:36.665120Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6700 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd1de932a6904f0e9606d37f159a99e9"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom typing import Optional, Union\nimport torch\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:36.667610Z","iopub.execute_input":"2023-07-25T12:17:36.668079Z","iopub.status.idle":"2023-07-25T12:17:40.013122Z","shell.execute_reply.started":"2023-07-25T12:17:36.668039Z","shell.execute_reply":"2023-07-25T12:17:40.012111Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:40.014392Z","iopub.execute_input":"2023-07-25T12:17:40.015368Z","iopub.status.idle":"2023-07-25T12:18:01.075925Z","shell.execute_reply.started":"2023-07-25T12:17:40.015329Z","shell.execute_reply":"2023-07-25T12:18:01.074931Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nSome weights of the model checkpoint at /kaggle/input/deberta-v3-large-hf-weights were not used when initializing DebertaV2ForMultipleChoice: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/deberta-v3-large-hf-weights and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_dir = 'finetuned_bert'\ntraining_args = TrainingArguments(\n    warmup_ratio=0.75,\n    output_dir=model_dir,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    learning_rate=5e-6,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=2,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    report_to='none'\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:18:01.077557Z","iopub.execute_input":"2023-07-25T12:18:01.077950Z","iopub.status.idle":"2023-07-25T12:18:01.169479Z","shell.execute_reply.started":"2023-07-25T12:18:01.077914Z","shell.execute_reply":"2023-07-25T12:18:01.168504Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_train_ds,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:13.622157Z","iopub.status.idle":"2023-07-25T12:17:13.622990Z","shell.execute_reply.started":"2023-07-25T12:17:13.622725Z","shell.execute_reply":"2023-07-25T12:17:13.622764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-25T12:17:13.624437Z","iopub.status.idle":"2023-07-25T12:17:13.625270Z","shell.execute_reply.started":"2023-07-25T12:17:13.624994Z","shell.execute_reply":"2023-07-25T12:17:13.625018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:58:48.048827Z","iopub.status.idle":"2023-07-24T06:58:48.049672Z","shell.execute_reply.started":"2023-07-24T06:58:48.049411Z","shell.execute_reply":"2023-07-24T06:58:48.049436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['answer'] = 'A'\n\n# Other than that we'll preprocess it in the same way we preprocessed test.csv\ntest_ds = Dataset.from_pandas(test_df)\ntokenized_test_ds = test_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:58:48.051335Z","iopub.status.idle":"2023-07-24T06:58:48.052163Z","shell.execute_reply.started":"2023-07-24T06:58:48.051909Z","shell.execute_reply":"2023-07-24T06:58:48.051932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = trainer.predict(tokenized_test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:58:48.053560Z","iopub.status.idle":"2023-07-24T06:58:48.054323Z","shell.execute_reply.started":"2023-07-24T06:58:48.054068Z","shell.execute_reply":"2023-07-24T06:58:48.054091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictions_to_map_output(predictions):\n    sorted_answer_indices = np.argsort(-predictions)\n    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:58:48.055665Z","iopub.status.idle":"2023-07-24T06:58:48.056428Z","shell.execute_reply.started":"2023-07-24T06:58:48.056171Z","shell.execute_reply":"2023-07-24T06:58:48.056194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = test_df[['id']]\nsubmission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:58:48.057756Z","iopub.status.idle":"2023-07-24T06:58:48.058528Z","shell.execute_reply.started":"2023-07-24T06:58:48.058272Z","shell.execute_reply":"2023-07-24T06:58:48.058307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}